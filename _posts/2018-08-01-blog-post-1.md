---
title: 'CS231n Note'
date: 2018-08-01
permalink: /posts/2018/08/cs231n/
tags:
  - computer vision
  - machine learning
  - deep learning
---

Here are the notes for `Convolutional Neural Networks for Visual Recognition`.

Lecture 1: Introduction to Convolutional Neural Networks for Visual Recognition 
------

Increasing computation (CPUs, GPUs) + Relative large high quality dataset (ImageNet) ---> CNN works very well 

Lecture 2: Image Classification
------

We want classifiers that are fast at prediction; slow for training is ok.

L1 distance has coordinate dependency.

Cross-Validation is useful for small datasets, but not used too frequently in deep learning.

Lecture 3: Loss Functions and Optimization
------

Multi-class SVM Classification: Given an example ($x_i$, $y_i$) where $x_i$ is the image and where $y_i$ is the (integer) label, and using the shorthand for the scores vector: $s = f(x_i, W)$.

The SVM loss has the form:

$L_i = \sum_{j \neq y_i}
\begin{cases} 
0,  & \mbox{if }s_{y_i} \ge s_j+1 \\
s_j-s_{y_i}+1, & \mbox{otherwise}
\end{cases}
=\sum_{j \neq y_i}\max(0, s_j-s_{y_i}+1)$


Lecture 4: Introduction to Neural Networks
------

Lecture 5: Convolutional Neural Networks
------

Lecture 6: Training Neural Networks I
------

Lecture 7: Training Neural Networks II
------

Lecture 8: Deep Learning Software
------

Lecture 9: CNN Architectures
------

Lecture 10: Recurrent Neural Networks
------

Lecture 11: Detection and Segmentation
------

Lecture 12: Visualizing and Understanding
------

Lecture 13: Generative Models
------

Lecture 14: Deep Reinforcement Learning
------

Lecture 15: Efficient Methods and Hardware for Deep Learning
------

Lecture 16: Adversarial Examples and Adversarial Training
------
