---
title: 'Introduction to Kubernetes'
date: 2018-08-01
permalink: /posts/2018/08/k8s_intro/
tags:
  - k8s
---

Here are the notes for [Introduction to Kubernetes]().

Container Orchestration
------

With a container image, we bundle the application along with its runtime and dependencies.

Kubernetes
------

Kubernetes offers a very rich set of features for container orchestration.

* Automatic binpacking

  Kubernetes automatically schedules the containers based on resource usage and constraints, without sacrificing the availability.
  
* Self-healing

  Kubernetes automatically replaces and reschedules the containers from failed nodes. It also kills and restarts the containers which do not respond to health checks, based on existing rules/policy.
  
* Horizontal scaling

  Kubernetes can automatically scale applications based on resource usage like CPU and memory. In some cases, it also supports dynamic scaling based on customer metrics.
  
* Service discovery and Load balancing

  Kubernetes groups sets of containers and refers to them via a Domain Name System (DNS). This DNS is also called a Kubernetes service. Kubernetes can discover these services automatically, and load-balance requests between containers of a given service.
  
* Automated rollouts and rollbacks

  Kubernetes can roll out and roll back new versions/configurations of an application, without introducing any downtime.  
  
* Secrets and configuration management

  Kubernetes can manage secrets and configuration details for an application without re-building the respective images. With secrets, we can share confidential information to our application without exposing it to the stack configuration, like on GitHub.
  
* Storage orchestration

  With Kubernetes and its plugins, we can automatically mount local, external, and storage solutions to the containers in a seamless manner, based on software-defined storage (SDS).  
  
* Batch execution

  Besides long running jobs, Kubernetes also supports batch execution. 
  
  
Kubernetes Architecture - Overview
------

<div  align="center">
<img src='/images/Kubernetes_Architecture.png'>
</div>
  
At a very high level, Kubernetes has the following main components:

* One or more master nodes

  A master node has the following components:
  
  * API server

      All the administrative tasks are performed via the API server within the master node. A user/operator sends REST commands to the API server, which then validates and processes the requests. After executing the requests, the resulting state of the cluster is stored in the distributed key-value store.
      
  * Scheduler

     As the name suggests, the scheduler schedules the work to different worker nodes. The scheduler has the resource usage information for each worker node. It also knows about the constraints that users/operators may have set, such as scheduling work on a node that has the label disk==ssd set. Before scheduling the work, the scheduler also takes into account the quality of the service requirements, data locality, affinity, anti-affinity, etc. The scheduler schedules the work in terms of Pods and Services.
  
  * Controller manager

      The controller manager manages different non-terminating control loops, which regulate the state of the Kubernetes cluster. Each one of these control loops knows about the desired state of the objects it manages, and watches their current state through the API server. In a control loop, if the current state of the objects it manages does not meet the desired state, then the control loop takes corrective steps to make sure that the current state is the same as the desired state.
  
  * etcd

     etcd is a distributed key-value store which is used to store the cluster state. It can be part of the Kubernetes Master, or, it can be configured externally, in which case, master nodes would connect to it.    
  
* One or more worker nodes  

  A worker node has the following components:
  
  * Container runtime

     To run and manage a container's lifecycle, we need a container runtime on the worker node. Some examples of container runtimes are: 
     
     * containerd

     * rkt

     * lxd
     
     Sometimes, Docker is also referred to as a container runtime, but to be precise, Docker is a platform which uses containerd as a container runtime. 
            
  * kubelet

     The kubelet is an agent which runs on each worker node and communicates with the master node. It receives the Pod definition via various means (primarily, through the API server), and runs the containers associated with the Pod. It also makes sure that the containers which are part of the Pods are healthy at all times.
     
     The kubelet connects to the container runtime using Container Runtime Interface (CRI). The Container Runtime Interface consists of protocol buffers, gRPC API, and libraries. 
     
     * CRI shims

         Below you will find some examples of CRI shims:
         
         * dockershim

             With dockershim, containers are created using Docker installed on the worker nodes. Internally, Docker uses containerd to create and manage containers.
             
         * cri-containerd

             With cri-containerd, we can directly use Docker's smaller offspring containerd to create and manage containers.    
             
         * CRI-O

             CRI-O enables using any Open Container Initiative (OCI) compatible runtimes with Kubernetes. At the time this course was created, CRI-O supported runC and Clear Containers as container runtimes. However, in principle, any OCI-compliant runtime can be plugged-in.
             
                                         
  * kube-proxy

     kube-proxy is the network proxy which runs on each worker node and listens to the API server for each Service endpoint creation/deletion.
    
* Distributed key-value store, like etcd

  In Kubernetes, besides storing the cluster state, etcd is also used to store configuration details such as subnets, ConfigMaps, Secrets, etc.   
  
  
To have a fully functional Kubernetes cluster, we need to make sure of the following:

* A unique IP is assigned to each Pod

  In Kubernetes, each Pod gets a unique IP address. For container networking, there are two primary specifications:
  
  * Container Network Model (CNM), proposed by Docker

  * Container Network Interface (CNI), proposed by CoreOS

  Kubernetes uses CNI to assign the IP address to each Pod.
  
  The container runtime offloads the IP assignment to CNI, which connects to the underlying configured plugin, like Bridge or MACvlan, to get the IP address. Once the IP address is given by the respective plugin, CNI forwards it back to the requested container runtime.

* Containers in a Pod can communicate to each other

  With the help of the underlying host operating system, all of the container runtimes generally create an isolated network entity for each container that it starts. On Linux, that entity is referred to as a network namespace. These network namespaces can be shared across containers, or with the host operating system.

  Inside a Pod, containers share the network namespaces, so that they can reach to each other via localhost.

* The Pod is able to communicate with other Pods in the cluster

  We can achieve this via:
  
  * Routable Pods and nodes, using the underlying physical infrastructure, like Google Kubernetes Engine

  * Using Software Defined Networking, like Flannel, Weave, Calico, etc

* If configured, the application deployed inside a Pod is accessible from the external world.

  By exposing our services to the external world with kube-proxy, we can access our applications from outside the cluster.
  
  
Installing Kubernetes
------
  
Kubernetes can be installed using different configurations. The four major installation types are briefly presented below:

* All-in-One Single-Node Installation

  With all-in-one, all the master and worker components are installed on a single node. This is very useful for learning, development, and testing. This type should not be used in production. Minikube is one such example.
  
* Single-Node etcd, Single-Master, and Multi-Worker Installation

  In this setup, we have a single master node, which also runs a single-node etcd instance. Multiple worker nodes are connected to the master node.
  
* Single-Node etcd, Multi-Master, and Multi-Worker Installation

  In this setup, we have multiple master nodes, which work in an HA mode, but we have a single-node etcd instance. Multiple worker nodes are connected to the master nodes.

* Multi-Node etcd, Multi-Master, and Multi-Worker Installation

  In this mode, etcd is configured in a clustered mode, outside the Kubernetes cluster, and the nodes connect to it. The master nodes are all configured in an HA mode, connecting to multiple worker nodes. This is the most advanced and recommended production setup.  
 

Accessing Minikube
------

Any healthy running Kubernetes cluster can be accessed via one of the following methods:

* Command Line Interface (CLI)

  kubectl is the Command Line Interface (CLI) tool to manage the Kubernetes cluster resources and applications.

* Graphical User Interface (GUI)

  The Kubernetes dashboard provides the Graphical User Interface (GUI) to interact with its resources and containerized applications.

* APIs

  Kubernetes has the API server, and operators/users connect to it from the external world to interact with the cluster. Using both CLI and GUI, we can connect to the API server on the master node to perform different operations. We can directly connect to the API server using its API endpoints and send commands to it, as long as we can access the master node and have the right credentials.
  
  
Kubernetes Building Blocks
------

With each object, we declare our intent or desired state using the `spec` field. The Kubernetes system manages the `status` field for objects, in which it records the actual state of the object. At any given point in time, the Kubernetes Control Plane tries to match the object's actual state to the object's desired state.

Examples of Kubernetes objects are Pods, ReplicaSets, Deployments, Namespaces, etc.

To create an object, we need to provide the `spec` field to the Kubernetes API server. The `spec` field describes the desired state, along with some basic information, like the name. The API request to create the object must have the `spec` field, as well as other details, in a JSON format. Most often, we provide an object's definition in a `.yaml` file, which is converted by `kubectl` in a JSON payload and sent to the API server.

Once the object is created, the Kubernetes system attaches the `status` field to the object.

* Pods

  A Pod is the smallest and simplest Kubernetes object. It is the unit of deployment in Kubernetes, which represents a single instance of the application. A Pod is a logical collection of one or more containers, which:
  
  * Are scheduled together on the same host
  * Share the same network namespace
  * Mount the same external storage (volumes)

  We attach the Pod's specification to other objects using Pods Templates.
    
  Pods are ephemeral in nature, and they do not have the capability to self-heal by themselves. That is why we use them with controllers, which can handle a Pod's replication, fault tolerance, self-heal, etc. Examples of controllers are Deployments, ReplicaSets, ReplicationControllers, etc. 
  
* ReplicationControllers  
  
  A ReplicationController (rc) is a controller that is part of the master node's controller manager.  
  
* ReplicaSets

  A ReplicaSet (rs) is the next-generation ReplicationController. ReplicaSets support both equality- and set-based selectors, whereas ReplicationControllers only support equality-based Selectors.
  
  ReplicaSets can be used independently, but they are mostly used by Deployments to orchestrate the Pod creation, deletion, and updates. A Deployment automatically creates the ReplicaSets, and we do not have to worry about managing them. 
  
* Deployments

  Deployment objects provide declarative updates to Pods and ReplicaSets. The DeploymentController is part of the master node's controller manager, and it makes sure that the current state always matches the desired state.
    
* Labels

  Labels are key-value pairs that can be attached to any Kubernetes objects (e.g. Pods). Labels are used to organize and select a subset of objects, based on the requirements in place. Many objects can have the same Label(s). Labels do not provide uniqueness to objects. 
  
* Namespace

  We can partition the Kubernetes cluster into sub-clusters using Namespaces. The names of the resources/objects created inside a Namespace are unique, but not across Namespaces.
  
  The `kube-system` Namespace contains the objects created by the Kubernetes system. 
  
  The `default` Namespace contains the objects which belong to any other Namespace. 
  
  `kube-public` is a special Namespace, which is readable by all users and used for special purposes, like bootstrapping a cluster. 