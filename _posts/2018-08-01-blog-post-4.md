---
title: 'Introduction to Kubernetes'
date: 2018-08-01
permalink: /posts/2018/08/k8s_intro/
tags:
  - k8s
---

Here are the notes for [Introduction to Kubernetes]().

Container Orchestration
------

With a container image, we bundle the application along with its runtime and dependencies.

Kubernetes
------

Kubernetes offers a very rich set of features for container orchestration.

* Automatic binpacking

  Kubernetes automatically schedules the containers based on resource usage and constraints, without sacrificing the availability.
  
* Self-healing

  Kubernetes automatically replaces and reschedules the containers from failed nodes. It also kills and restarts the containers which do not respond to health checks, based on existing rules/policy.
  
* Horizontal scaling

  Kubernetes can automatically scale applications based on resource usage like CPU and memory. In some cases, it also supports dynamic scaling based on customer metrics.
  
* Service discovery and Load balancing

  Kubernetes groups sets of containers and refers to them via a Domain Name System (DNS). This DNS is also called a Kubernetes service. Kubernetes can discover these services automatically, and load-balance requests between containers of a given service.
  
* Automated rollouts and rollbacks

  Kubernetes can roll out and roll back new versions/configurations of an application, without introducing any downtime.  
  
* Secrets and configuration management

  Kubernetes can manage secrets and configuration details for an application without re-building the respective images. With secrets, we can share confidential information to our application without exposing it to the stack configuration, like on GitHub.
  
* Storage orchestration

  With Kubernetes and its plugins, we can automatically mount local, external, and storage solutions to the containers in a seamless manner, based on software-defined storage (SDS).  
  
* Batch execution

  Besides long running jobs, Kubernetes also supports batch execution. 
  
  
Kubernetes Architecture - Overview
------

<div  align="center">
<img src='/images/Kubernetes_Architecture.png'>
</div>
  
At a very high level, Kubernetes has the following main components:

* One or more master nodes

  A master node has the following components:
  
  * API server

      All the administrative tasks are performed via the API server within the master node. A user/operator sends REST commands to the API server, which then validates and processes the requests. After executing the requests, the resulting state of the cluster is stored in the distributed key-value store.
      
  * Scheduler

     As the name suggests, the scheduler schedules the work to different worker nodes. The scheduler has the resource usage information for each worker node. It also knows about the constraints that users/operators may have set, such as scheduling work on a node that has the label disk==ssd set. Before scheduling the work, the scheduler also takes into account the quality of the service requirements, data locality, affinity, anti-affinity, etc. The scheduler schedules the work in terms of Pods and Services.
  
  * Controller manager

      The controller manager manages different non-terminating control loops, which regulate the state of the Kubernetes cluster. Each one of these control loops knows about the desired state of the objects it manages, and watches their current state through the API server. In a control loop, if the current state of the objects it manages does not meet the desired state, then the control loop takes corrective steps to make sure that the current state is the same as the desired state.
  
  * etcd

     etcd is a distributed key-value store which is used to store the cluster state. It can be part of the Kubernetes Master, or, it can be configured externally, in which case, master nodes would connect to it.    
  
* One or more worker nodes  

  A worker node has the following components:
  
  * Container runtime

     To run and manage a container's lifecycle, we need a container runtime on the worker node. Some examples of container runtimes are: 
     
     * containerd

     * rkt

     * lxd
     
     Sometimes, Docker is also referred to as a container runtime, but to be precise, Docker is a platform which uses containerd as a container runtime. 
            
  * kubelet

     The kubelet is an agent which runs on each worker node and communicates with the master node. It receives the Pod definition via various means (primarily, through the API server), and runs the containers associated with the Pod. It also makes sure that the containers which are part of the Pods are healthy at all times.
     
     The kubelet connects to the container runtime using Container Runtime Interface (CRI). The Container Runtime Interface consists of protocol buffers, gRPC API, and libraries. 
     
     * CRI shims

         Below you will find some examples of CRI shims:
         
         * dockershim

             With dockershim, containers are created using Docker installed on the worker nodes. Internally, Docker uses containerd to create and manage containers.
             
         * cri-containerd

             With cri-containerd, we can directly use Docker's smaller offspring containerd to create and manage containers.    
             
         * CRI-O

             CRI-O enables using any Open Container Initiative (OCI) compatible runtimes with Kubernetes. At the time this course was created, CRI-O supported runC and Clear Containers as container runtimes. However, in principle, any OCI-compliant runtime can be plugged-in.
             
                                         
  * kube-proxy

     kube-proxy is the network proxy which runs on each worker node and listens to the API server for each Service endpoint creation/deletion.
    
* Distributed key-value store, like etcd

  In Kubernetes, besides storing the cluster state, etcd is also used to store configuration details such as subnets, ConfigMaps, Secrets, etc.   
  
  
To have a fully functional Kubernetes cluster, we need to make sure of the following:

* A unique IP is assigned to each Pod

  In Kubernetes, each Pod gets a unique IP address. For container networking, there are two primary specifications:
  
  * Container Network Model (CNM), proposed by Docker

  * Container Network Interface (CNI), proposed by CoreOS

  Kubernetes uses CNI to assign the IP address to each Pod.
  
  The container runtime offloads the IP assignment to CNI, which connects to the underlying configured plugin, like Bridge or MACvlan, to get the IP address. Once the IP address is given by the respective plugin, CNI forwards it back to the requested container runtime.

* Containers in a Pod can communicate to each other

  With the help of the underlying host operating system, all of the container runtimes generally create an isolated network entity for each container that it starts. On Linux, that entity is referred to as a network namespace. These network namespaces can be shared across containers, or with the host operating system.

  Inside a Pod, containers share the network namespaces, so that they can reach to each other via localhost.

* The Pod is able to communicate with other Pods in the cluster

  We can achieve this via:
  
  * Routable Pods and nodes, using the underlying physical infrastructure, like Google Kubernetes Engine

  * Using Software Defined Networking, like Flannel, Weave, Calico, etc

* If configured, the application deployed inside a Pod is accessible from the external world.

  By exposing our services to the external world with kube-proxy, we can access our applications from outside the cluster.
  
  
Installing Kubernetes
------
  
Kubernetes can be installed using different configurations. The four major installation types are briefly presented below:

* All-in-One Single-Node Installation

  With all-in-one, all the master and worker components are installed on a single node. This is very useful for learning, development, and testing. This type should not be used in production. Minikube is one such example.
  
* Single-Node etcd, Single-Master, and Multi-Worker Installation

  In this setup, we have a single master node, which also runs a single-node etcd instance. Multiple worker nodes are connected to the master node.
  
* Single-Node etcd, Multi-Master, and Multi-Worker Installation

  In this setup, we have multiple master nodes, which work in an HA mode, but we have a single-node etcd instance. Multiple worker nodes are connected to the master nodes.

* Multi-Node etcd, Multi-Master, and Multi-Worker Installation

  In this mode, etcd is configured in a clustered mode, outside the Kubernetes cluster, and the nodes connect to it. The master nodes are all configured in an HA mode, connecting to multiple worker nodes. This is the most advanced and recommended production setup.  
  
  
  
  
  
  